{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Deploying Strands Agents to AWS Bedrock AgentCore\n",
    "\n",
    "This notebook demonstrates how to deploy Strands Agents agent to AWS Bedrock AgentCore using direct boto3 API calls. It also enables you to visualize the agent's decision-making process in the GenAI Observability dashboard in Amazon CloudWatch.\n",
    "\n",
    "If you're not familiar with the Strands Agents SDK, check out the [official documentation](https://strandsagents.com).\n",
    "\n",
    "To can access the Amazon Bedrock AgentCore Developer Guide, check out the [AWS documentation](https://docs.aws.amazon.com/bedrock-agentcore/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Python 3.12 or later\n",
    "- boto3 1.39 or later\n",
    "- AWS CLI installed and configured with appropriate permissions\n",
    "\n",
    "In addition, you should have the following readily available:\n",
    "- Amazon S3 bucket to package code\n",
    "- AWS IAM role for automation access\n",
    "- Knowledge bases are fully synched\n",
    "- External functions for enterprise systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Install required packages\n",
    "\n",
    "Ensure you have the latest versions required installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade boto3\n",
    "!pip install boto3 botocore --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import required libraries\n",
    "\n",
    "Import all necessary Python libraries for AWS interactions and file handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import string\n",
    "import random\n",
    "import zipfile\n",
    "import tempfile\n",
    "import collections\n",
    "import boto3\n",
    "import botocore\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set required parameters\n",
    "\n",
    "Update the parameters below using your environment specific details. These parameters will be used throughout the notebook for creating and configuring the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Knowledge_Base_1_Id = '<provide 1st Knowledge Base Id>'\n",
    "Knowledge_Base_2_Id = '<provide 2nd Knowledge Base Id>'\n",
    "System_Function_1_Name = '<provide 1st System Function Name>'\n",
    "System_Function_2_Name = '<provide 2nd System Function Name>'\n",
    "Agent_Directory_Name = '<provide agent directory name based on event use case>'\n",
    "CodeBucketForAutomationName = '<provide CodeBucketForAutomationName - not full ARN>'\n",
    "SolutionAccessRoleArn = '<provide SolutionAccessRoleArn>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify agent code requirements\n",
    "\n",
    "We'll check that necessary files for the agent exist in the expected locations before proceeding with the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify AgentCore entrypoint exists\n",
    "agentcore_entrypoint_file = Path(f\"{Agent_Directory_Name}/agentcore_entrypoint.py\")\n",
    "if agentcore_entrypoint_file.exists():\n",
    "    print(f\"AgentCore entrypoint found at {agentcore_entrypoint_file}\")\n",
    "else:\n",
    "    print(f\"AgentCore entrypoint not found at {agentcore_entrypoint_file}\")\n",
    "\n",
    "# Verify requirements file exists\n",
    "requirements_file = Path(f\"{Agent_Directory_Name}/requirements.txt\")\n",
    "if requirements_file.exists():\n",
    "    print(f\"Requirements file found at {requirements_file}\")\n",
    "else:\n",
    "    print(f\"Requirements file not found at {requirements_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: Create Dockerfile for Agent\n",
    "\n",
    "We need to create a Dockerfile to package the agent for deployment to AgentCore Runtime. This Dockerfile will include all necessary dependencies and configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dockerfile():\n",
    "    '''Create a Dockerfile for AgentCore Runtime'''\n",
    "    dockerfile_content = f'''\n",
    "FROM --platform=linux/arm64 public.ecr.aws/docker/library/python:3.12-slim-bookworm\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy requirements and install dependencies\n",
    "COPY {Agent_Directory_Name}/requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "RUN pip install bedrock-agentcore\n",
    "RUN pip install aws-opentelemetry-distro\n",
    "\n",
    "# Copy agent code and tools\n",
    "COPY {Agent_Directory_Name}/*.py ./\n",
    "\n",
    "# Set default AWS region\n",
    "ENV AWS_DEFAULT_REGION=${{AWS_DEFAULT_REGION}}\n",
    "\n",
    "# Set agent resources variables\n",
    "ENV KNOWLEDGE_BASE_1_ID=${{KNOWLEDGE_BASE_1_ID}}\n",
    "ENV KNOWLEDGE_BASE_2_ID=${{KNOWLEDGE_BASE_2_ID}}\n",
    "ENV SYSTEM_FUNCTION_1_NAME=${{SYSTEM_FUNCTION_1_NAME}}\n",
    "ENV SYSTEM_FUNCTION_2_NAME=${{SYSTEM_FUNCTION_2_NAME}}\n",
    "\n",
    "# OpenTelemetry Configuration for AWS CloudWatch GenAI Observability\n",
    "ENV OTEL_PYTHON_DISTRO=aws_distro\n",
    "ENV OTEL_PYTHON_CONFIGURATOR=aws_configurator\n",
    "ENV OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf\n",
    "ENV OTEL_TRACES_EXPORTER=otlp\n",
    "ENV OTEL_EXPORTER_OTLP_LOGS_HEADERS=x-aws-log-group=agents/strands-agent-logs,x-aws-log-stream=default,x-aws-metric-namespace=agents\n",
    "ENV OTEL_RESOURCE_ATTRIBUTES=service.name=strands-agent\n",
    "ENV AGENT_OBSERVABILITY_ENABLED=true\n",
    "\n",
    "# Expose the port that AgentCore Runtime expects\n",
    "EXPOSE 8080\n",
    "\n",
    "# Run the agent\n",
    "CMD [\"opentelemetry-instrument\", \"python\", \"agentcore_entrypoint.py\"]\n",
    "'''\n",
    "    \n",
    "    # Write the Dockerfile\n",
    "    dockerfile_path = Path(\"Dockerfile\")\n",
    "    with open(dockerfile_path, 'w') as f:\n",
    "        f.write(dockerfile_content)\n",
    "    \n",
    "    return dockerfile_path\n",
    "\n",
    "# Create the Dockerfile\n",
    "dockerfile_path = create_dockerfile()\n",
    "print(f\"Dockerfile created at {dockerfile_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build Docker image using SageMaker Docker Build CLI\n",
    "\n",
    "Use the SageMaker Docker Build CLI to build and push our Docker image to Amazon ECR. This tool handles the Docker build process in the background using AWS CodeBuild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define required functions for building arm64 container image\n",
    "\n",
    "Position = collections.namedtuple(\"Position\", [\"timestamp\", \"skip\"])\n",
    "\n",
    "def _log_stream(client, log_group, stream_name, position):\n",
    "    start_time, skip = position\n",
    "    next_token = None\n",
    "    event_count = 1\n",
    "    while event_count > 0:\n",
    "        token_arg = {\"nextToken\": next_token} if next_token else {}\n",
    "        response = client.get_log_events(\n",
    "            logGroupName=log_group, logStreamName=stream_name,\n",
    "            startTime=start_time, startFromHead=True, **token_arg\n",
    "        )\n",
    "        next_token = response[\"nextForwardToken\"]\n",
    "        events = response[\"events\"]\n",
    "        event_count = len(events)\n",
    "        if event_count > skip:\n",
    "            events = events[skip:]\n",
    "            skip = 0\n",
    "        else:\n",
    "            skip = skip - event_count\n",
    "            events = []\n",
    "        for ev in events:\n",
    "            ts, count = position\n",
    "            if ev[\"timestamp\"] == ts:\n",
    "                position = Position(timestamp=ts, skip=count + 1)\n",
    "            else:\n",
    "                position = Position(timestamp=ev[\"timestamp\"], skip=1)\n",
    "            yield ev, position\n",
    "\n",
    "def _logs_for_build(build_id, session, wait=False, poll=10):\n",
    "    codebuild = session.client(\"codebuild\")\n",
    "    description = codebuild.batch_get_builds(ids=[build_id])[\"builds\"][0]\n",
    "    status = description[\"buildStatus\"]\n",
    "    log_group = description[\"logs\"].get(\"groupName\")\n",
    "    stream_name = description[\"logs\"].get(\"streamName\")\n",
    "    position = Position(timestamp=0, skip=0)\n",
    "    config = botocore.config.Config(retries={\"max_attempts\": 15})\n",
    "    client = session.client(\"logs\", config=config)\n",
    "    \n",
    "    while log_group is None and status == \"IN_PROGRESS\":\n",
    "        time.sleep(poll)\n",
    "        description = codebuild.batch_get_builds(ids=[build_id])[\"builds\"][0]\n",
    "        log_group = description[\"logs\"].get(\"groupName\")\n",
    "        stream_name = description[\"logs\"].get(\"streamName\")\n",
    "        status = description[\"buildStatus\"]\n",
    "    \n",
    "    last_describe_job_call = time.time()\n",
    "    dot_printed = False\n",
    "    dot = True\n",
    "    \n",
    "    while True:\n",
    "        for event, position in _log_stream(client, log_group, stream_name, position):\n",
    "            print(event[\"message\"].rstrip())\n",
    "            if dot:\n",
    "                dot = False\n",
    "                if dot_printed:\n",
    "                    print()\n",
    "        \n",
    "        if not wait or status != \"IN_PROGRESS\":\n",
    "            break\n",
    "            \n",
    "        time.sleep(poll)\n",
    "        if dot:\n",
    "            print(\".\", end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            dot_printed = True\n",
    "            \n",
    "        if time.time() - last_describe_job_call >= 30:\n",
    "            description = codebuild.batch_get_builds(ids=[build_id])[\"builds\"][0]\n",
    "            status = description[\"buildStatus\"]\n",
    "            last_describe_job_call = time.time()\n",
    "            if status != \"IN_PROGRESS\":\n",
    "                print()\n",
    "                break\n",
    "\n",
    "def build_arm64_image(role, bucket, repository_name, verbose=False):\n",
    "    session = boto3.Session()\n",
    "    account_id = session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "    region = session.region_name\n",
    "    \n",
    "    # Upload source code\n",
    "    random_suffix = \"\".join(random.choices(string.ascii_letters, k=16))\n",
    "    key = f\"codebuild-{random_suffix}.zip\"\n",
    "    \n",
    "    with tempfile.TemporaryFile() as tmp:\n",
    "        with zipfile.ZipFile(tmp, \"w\") as zip:\n",
    "            for dirname, _, filelist in os.walk(\".\"):\n",
    "                for file in filelist:\n",
    "                    zip.write(f\"{dirname}/{file}\")\n",
    "            # Add buildspec for ARM64\n",
    "            buildspec = \"\"\"version: 0.2\n",
    "phases:\n",
    "  pre_build:\n",
    "    commands:\n",
    "      - echo Logging in to Amazon ECR...\n",
    "      - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
    "      - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin 763104351884.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
    "      - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin 217643126080.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
    "      - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin 727897471807.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
    "      - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin 626614931356.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
    "      - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin 683313688378.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
    "      - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin 520713654638.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
    "      - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin 462105765813.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
    "  build:\n",
    "    commands:\n",
    "      - echo Build started on `date`\n",
    "      - echo Building the Docker image...\n",
    "      - docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .\n",
    "      - docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "  post_build:\n",
    "    commands:\n",
    "      - echo Build completed on `date`\n",
    "      - echo Pushing the Docker image...\n",
    "      - docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\"\"\"\n",
    "            zip.writestr(\"buildspec.yml\", buildspec)\n",
    "        tmp.seek(0)\n",
    "        session.client(\"s3\").upload_fileobj(tmp, bucket, key)\n",
    "    \n",
    "    # Create ECR repo\n",
    "    try:\n",
    "        session.client(\"ecr\").create_repository(repositoryName=repository_name)\n",
    "        print(f\"Created ECR repository {repository_name}\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Create and run CodeBuild project\n",
    "    project_name = f\"build-{random_suffix}\"\n",
    "    codebuild = session.client(\"codebuild\")\n",
    "    \n",
    "    codebuild.create_project(\n",
    "        name=project_name,\n",
    "        source={\"type\": \"S3\", \"location\": f\"{bucket}/{key}\"},\n",
    "        artifacts={\"type\": \"NO_ARTIFACTS\"},\n",
    "        environment={\n",
    "            \"type\": \"ARM_CONTAINER\",\n",
    "            \"image\": \"aws/codebuild/amazonlinux2-aarch64-standard:3.0\",\n",
    "            \"computeType\": \"BUILD_GENERAL1_SMALL\",\n",
    "            \"environmentVariables\": [\n",
    "                {\"name\": \"AWS_DEFAULT_REGION\", \"value\": region},\n",
    "                {\"name\": \"AWS_ACCOUNT_ID\", \"value\": account_id},\n",
    "                {\"name\": \"IMAGE_REPO_NAME\", \"value\": repository_name},\n",
    "                {\"name\": \"IMAGE_TAG\", \"value\": \"latest\"},\n",
    "            ],\n",
    "            \"privilegedMode\": True,\n",
    "        },\n",
    "        serviceRole=f\"arn:aws:iam::{account_id}:role/{role}\",\n",
    "    )\n",
    "    \n",
    "    build_id = codebuild.start_build(projectName=project_name)[\"build\"][\"id\"]\n",
    "    print(f\"Starting build {build_id} with verbose={verbose}\")\n",
    "    \n",
    "    if verbose:\n",
    "        # Stream logs using library implementation\n",
    "        _logs_for_build(build_id, session, wait=True)\n",
    "    else:\n",
    "        # Just wait for completion without streaming logs\n",
    "        while True:\n",
    "            build_info = codebuild.batch_get_builds(ids=[build_id])[\"builds\"][0]\n",
    "            status = build_info[\"buildStatus\"]\n",
    "            if status != \"IN_PROGRESS\":\n",
    "                break\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            time.sleep(30)\n",
    "        print()\n",
    "\n",
    "    # Get final status\n",
    "    build_info = codebuild.batch_get_builds(ids=[build_id])[\"builds\"][0]\n",
    "    status = build_info[\"buildStatus\"]\n",
    "    print(f\"Build complete, status = {status}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    codebuild.delete_project(name=project_name)\n",
    "    session.client(\"s3\").delete_object(Bucket=bucket, Key=key)\n",
    "    \n",
    "    if status == \"SUCCEEDED\":\n",
    "        ecr_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{repository_name}:latest\"\n",
    "        print(f\"Image URI: {ecr_uri}\")\n",
    "        return ecr_uri\n",
    "    else:\n",
    "        raise Exception(f\"Build failed with status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kick start building arm64 container image\n",
    "role_name = SolutionAccessRoleArn.split('/')[-1]\n",
    "repository_name = \"strands-agent-repo\"\n",
    "ecr_uri = build_arm64_image(role_name, CodeBucketForAutomationName, repository_name)\n",
    "\n",
    "# Verify the image exists in ECR\n",
    "try:\n",
    "    ecr_client = boto3.client('ecr')\n",
    "    response = ecr_client.describe_images(\n",
    "        repositoryName=repository_name,\n",
    "        imageIds=[{'imageTag': 'latest'}]\n",
    "    )\n",
    "    print(f\"Image verified in repository: {repository_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error verifying image: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Deploy AgentCore Runtime\n",
    "\n",
    "Create the AgentCore Runtime using boto3 APIs with the Docker image we built in the previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or Update AgentCore Runtime\n",
    "existing_runtime = None\n",
    "region = boto3.Session().region_name\n",
    "agent_runtime_name = \"StrandsAgentCoreRuntime\"\n",
    "agentcore_control_client = boto3.client('bedrock-agentcore-control')\n",
    "\n",
    "# Try to get existing agent runtime first\n",
    "list_response = agentcore_control_client.list_agent_runtimes()\n",
    "for runtime in list_response.get('agentRuntimes', []):\n",
    "    if runtime['agentRuntimeName'] == agent_runtime_name:\n",
    "        existing_runtime = runtime\n",
    "        agent_runtime_id = existing_runtime['agentRuntimeId']\n",
    "        agent_runtime_arn = existing_runtime['agentRuntimeArn']\n",
    "        print(f\"Found existing AgentCore Runtime ID: {agent_runtime_id}\")\n",
    "\n",
    "if existing_runtime: # Update the existing runtim\n",
    "    update_response = agentcore_control_client.update_agent_runtime(\n",
    "        agentRuntimeId=agent_runtime_id,\n",
    "        roleArn=SolutionAccessRoleArn,\n",
    "        agentRuntimeArtifact={\n",
    "            \"containerConfiguration\": {\n",
    "                \"containerUri\": ecr_uri\n",
    "            }\n",
    "        },            \n",
    "        networkConfiguration={\n",
    "            \"networkMode\": \"PUBLIC\"\n",
    "        },\n",
    "        environmentVariables={\n",
    "            \"AWS_DEFAULT_REGION\": region,\n",
    "            \"KNOWLEDGE_BASE_1_ID\": Knowledge_Base_1_Id,\n",
    "            \"KNOWLEDGE_BASE_2_ID\": Knowledge_Base_2_Id,\n",
    "            \"SYSTEM_FUNCTION_1_NAME\": System_Function_1_Name,\n",
    "            \"SYSTEM_FUNCTION_2_NAME\": System_Function_2_Name\n",
    "        }\n",
    "    )\n",
    "    print(f\"Updated existing AgentCore Runtime\")\n",
    "else: # Create new runtime\n",
    "    create_response = agentcore_control_client.create_agent_runtime(\n",
    "        agentRuntimeName=agent_runtime_name,\n",
    "        roleArn=SolutionAccessRoleArn,\n",
    "        agentRuntimeArtifact={\n",
    "            \"containerConfiguration\": {\n",
    "                \"containerUri\": ecr_uri\n",
    "            }\n",
    "        },\n",
    "        networkConfiguration={\n",
    "            \"networkMode\": \"PUBLIC\"\n",
    "        },\n",
    "        environmentVariables={\n",
    "            \"AWS_DEFAULT_REGION\": region,\n",
    "            \"KNOWLEDGE_BASE_1_ID\": Knowledge_Base_1_Id,\n",
    "            \"KNOWLEDGE_BASE_2_ID\": Knowledge_Base_2_Id,\n",
    "            \"SYSTEM_FUNCTION_1_NAME\": System_Function_1_Name,\n",
    "            \"SYSTEM_FUNCTION_2_NAME\": System_Function_2_Name\n",
    "        }\n",
    "    )\n",
    "    agent_runtime_id = create_response['agentRuntimeId']\n",
    "    agent_runtime_arn = create_response['agentRuntimeArn']\n",
    "    print(f\"Created new AgentCore Runtime ID: {agent_runtime_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Check AgentCore Runtime Status\n",
    "\n",
    "Monitor the status of the AgentCore Runtime until ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_runtime_status(agent_runtime_id):\n",
    "    \"\"\"Check the status of the AgentCore Runtime\"\"\"\n",
    "    response = agentcore_control_client.get_agent_runtime(\n",
    "        agentRuntimeId=agent_runtime_id\n",
    "    )\n",
    "    return response['status']\n",
    "\n",
    "# Wait for the runtime to be ready\n",
    "print(\"Waiting for AgentCore Runtime to be ready...\")\n",
    "runtime_status = check_runtime_status(agent_runtime_id)\n",
    "while runtime_status not in ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']:\n",
    "    print(f\"Runtime status: {runtime_status}\")\n",
    "    time.sleep(10)\n",
    "    runtime_status = check_runtime_status(agent_runtime_id)\n",
    "print(f\"Runtime status: {runtime_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Test Agent Runtime Deployment\n",
    "\n",
    "Send a test prompt to the AgentCore Runtime to verify that the agent is live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client for the AgentCore data plane\n",
    "agentcore_client = boto3.client('bedrock-agentcore')\n",
    "\n",
    "# Test the AgentCore Runtime with a sample query\n",
    "try:\n",
    "    invoke_response = agentcore_client.invoke_agent_runtime(\n",
    "        agentRuntimeArn=agent_runtime_arn,\n",
    "        qualifier=\"DEFAULT\",\n",
    "        traceId=str(uuid.uuid4()),\n",
    "        contentType=\"application/json\",\n",
    "        payload=json.dumps({\"prompt\": \"A new user is asking about the price of Doggy Delights\"})\n",
    "    )\n",
    "    \n",
    "    # Process the response\n",
    "    if \"text/event-stream\" in invoke_response.get(\"contentType\", \"\"):\n",
    "        content = []\n",
    "        for line in invoke_response[\"response\"].iter_lines(chunk_size=1):\n",
    "            if line:\n",
    "                line = line.decode(\"utf-8\")\n",
    "                if line.startswith(\"data: \"):\n",
    "                    line = line[6:]\n",
    "                    content.append(line)\n",
    "        response_text = \"\\n\".join(content)\n",
    "    else:\n",
    "        events = []\n",
    "        for event in invoke_response.get(\"response\", []):\n",
    "            events.append(event)\n",
    "        \n",
    "        # Combine all events to fix truncation\n",
    "        combined_content = \"\"\n",
    "        for event in events:\n",
    "            combined_content += event.decode(\"utf-8\")\n",
    "        \n",
    "        response_text = json.loads(combined_content)\n",
    "    print(\"Agent Response:\")\n",
    "    print(response_text)\n",
    "except Exception as e:\n",
    "    print(f\"Error invoking AgentCore Runtime: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’¡ Pro Tip: This notebook enables monitoring and tracing capabilities using AWS OpenTelemetry Python Distro. To visualize the agent's decision-making process and gain insights into its performance, go to the GenAI Observability dashboard in Amazon CloudWatch. Click through the various features of the GenAI observability dashboard to get more detailed information on traces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Cleanup Resources (Optional)\n",
    "\n",
    "Clean up the AWS resources created in this notebook to avoid incurring unnecessary charges by uncommenting the last line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_resources():\n",
    "    '''Clean up AWS resources created in this notebook.'''  \n",
    "    # Delete the AgentCore Runtime\n",
    "    try:\n",
    "        agentcore_control_client.delete_agent_runtime(\n",
    "            agentRuntimeId=agent_runtime_id\n",
    "        )\n",
    "        print(f\"Initiated deletion of AgentCore Runtime: {agent_runtime_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting AgentCore Runtime: {agent_runtime_id}\")\n",
    "    \n",
    "    # Delete the ECR repository\n",
    "    try:\n",
    "        ecr_client = boto3.client('ecr')\n",
    "        ecr_client.delete_repository(\n",
    "            repositoryName=repository_name,\n",
    "            force=True  # Force deletion even if it contains images\n",
    "        )\n",
    "        print(f\"Deleted ECR repository: {repository_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting ECR repository: {repository_name}\")\n",
    "    \n",
    "    # Remove the Dockerfile\n",
    "    try:\n",
    "        if os.path.exists('Dockerfile'):\n",
    "            os.remove('Dockerfile')\n",
    "            print(\"Deleted Dockerfile\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting Dockerfile\")\n",
    "\n",
    "# Uncomment the line below to clean up resources\n",
    "# cleanup_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we demonstrated how to:\n",
    "\n",
    "1. Package the agent code into a Docker container\n",
    "2. Deploy the agent to AgentCore Runtime using direct boto3 API calls\n",
    "3. Test the deployed agent using AgentCore Runtime Endpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
